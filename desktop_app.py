"""
Parbiomech ë¹„ë””ì˜¤ ë¶„ì„ ë°ìŠ¤í¬í†± ì• í”Œë¦¬ì¼€ì´ì…˜
PyQt5 ê¸°ë°˜ GUI í”„ë¡œê·¸ë¨
"""

import sys
import os
import tempfile
from pathlib import Path

from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QPushButton, QLabel, QFileDialog, QProgressBar, QTableWidget,
    QTableWidgetItem, QTabWidget, QSlider, QSpinBox, QGroupBox,
    QMessageBox, QTextEdit, QSplitter
)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QTimer
from PyQt5.QtGui import QFont, QPixmap, QImage
import cv2
import numpy as np
import mediapipe as mp
import pandas as pd
import pyqtgraph as pg

# MediaPipe ì„¤ì •
os.environ['MEDIAPIPE_RESOURCE_CACHE_DIR'] = tempfile.gettempdir()
os.environ['MEDIAPIPE_DISABLE_GPU'] = '1'

mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles


class VideoAnalysisThread(QThread):
    """ë¹„ë””ì˜¤ ë¶„ì„ì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰"""
    progress = pyqtSignal(int)
    status = pyqtSignal(str)
    finished = pyqtSignal(dict)
    error = pyqtSignal(str)
    
    def __init__(self, video_path, timepoints, confidence):
        super().__init__()
        self.video_path = video_path
        self.timepoints = timepoints
        self.confidence = confidence
        
    def run(self):
        try:
            result = self.process_video()
            self.finished.emit(result)
        except Exception as e:
            self.error.emit(str(e))
    
    def process_video(self):
        """ë¹„ë””ì˜¤ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜"""
        self.status.emit("ë¹„ë””ì˜¤ ë¡œë“œ ì¤‘...")
        
        cap = cv2.VideoCapture(self.video_path)
        if not cap.isOpened():
            raise Exception("ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # ì¶œë ¥ ë¹„ë””ì˜¤ ì¤€ë¹„
        output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        output_path = output_file.name
        output_file.close()
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        tracking_data = []
        timepoint_results = {}
        
        self.status.emit("í¬ì¦ˆ ë¶„ì„ ì¤‘...")
        
        with mp_pose.Pose(
            min_detection_confidence=self.confidence,
            min_tracking_confidence=self.confidence,
            model_complexity=0
        ) as pose:
            
            frame_count = 0
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                # RGB ë³€í™˜
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                image.flags.writeable = False
                
                # í¬ì¦ˆ ê°ì§€
                results = pose.process(image)
                
                # ë‹¤ì‹œ BGRë¡œ
                image.flags.writeable = True
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
                
                # ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
                if results.pose_landmarks:
                    mp_drawing.draw_landmarks(
                        image,
                        results.pose_landmarks,
                        mp_pose.POSE_CONNECTIONS,
                        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()
                    )
                    
                    # ëœë“œë§ˆí¬ ë°ì´í„° ì €ì¥
                    landmarks = results.pose_landmarks.landmark
                    tracking_data.append({
                        'frame': frame_count,
                        'time': frame_count / fps,
                        'nose_x': landmarks[0].x,
                        'nose_y': landmarks[0].y,
                        'left_shoulder_x': landmarks[11].x,
                        'left_shoulder_y': landmarks[11].y,
                        'right_shoulder_x': landmarks[12].x,
                        'right_shoulder_y': landmarks[12].y,
                        'left_elbow_x': landmarks[13].x,
                        'left_elbow_y': landmarks[13].y,
                        'right_elbow_x': landmarks[14].x,
                        'right_elbow_y': landmarks[14].y,
                        'left_wrist_x': landmarks[15].x,
                        'left_wrist_y': landmarks[15].y,
                        'right_wrist_x': landmarks[16].x,
                        'right_wrist_y': landmarks[16].y,
                        'left_hip_x': landmarks[23].x,
                        'left_hip_y': landmarks[23].y,
                        'right_hip_x': landmarks[24].x,
                        'right_hip_y': landmarks[24].y,
                        'left_knee_x': landmarks[25].x,
                        'left_knee_y': landmarks[25].y,
                        'right_knee_x': landmarks[26].x,
                        'right_knee_y': landmarks[26].y,
                        'left_ankle_x': landmarks[27].x,
                        'left_ankle_y': landmarks[27].y,
                        'right_ankle_x': landmarks[28].x,
                        'right_ankle_y': landmarks[28].y,
                    })
                
                # ë¹„ë””ì˜¤ì— ì§ì ‘ ì“°ê¸°
                out.write(image)
                
                frame_count += 1
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress_pct = int((frame_count / total_frames) * 100)
                self.progress.emit(progress_pct)
                
                if frame_count % 30 == 0:
                    self.status.emit(f"ì²˜ë¦¬ ì¤‘: {frame_count}/{total_frames} í”„ë ˆì„")
        
        cap.release()
        out.release()
        
        # íƒ€ì„í¬ì¸íŠ¸ ë¶„ì„
        self.status.emit("íƒ€ì„í¬ì¸íŠ¸ ë¶„ì„ ì¤‘...")
        df_tracking = pd.DataFrame(tracking_data)
        
        for tp in self.timepoints:
            target_frame = int(tp * fps)
            if target_frame < len(tracking_data):
                data = tracking_data[target_frame]
                
                # ê°ë„ ê³„ì‚° (ì˜ˆì‹œ: ì™¼ìª½ íŒ”ê¿ˆì¹˜)
                shoulder = np.array([data['left_shoulder_x'], data['left_shoulder_y']])
                elbow = np.array([data['left_elbow_x'], data['left_elbow_y']])
                wrist = np.array([data['left_wrist_x'], data['left_wrist_y']])
                
                angle = self.calculate_angle(shoulder, elbow, wrist)
                
                timepoint_results[tp] = {
                    'left_elbow_angle': angle,
                    'frame': target_frame
                }
        
        self.status.emit("ë¶„ì„ ì™„ë£Œ!")
        self.progress.emit(100)
        
        return {
            'output_video': output_path,
            'tracking_data': df_tracking,
            'timepoint_results': timepoint_results,
            'fps': fps
        }
    
    def calculate_angle(self, point1, point2, point3):
        """ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°"""
        vector1 = point1 - point2
        vector2 = point3 - point2
        
        dot_product = np.dot(vector1, vector2)
        magnitude1 = np.linalg.norm(vector1)
        magnitude2 = np.linalg.norm(vector2)
        
        if magnitude1 == 0 or magnitude2 == 0:
            return 0
        
        cos_angle = dot_product / (magnitude1 * magnitude2)
        cos_angle = np.clip(cos_angle, -1.0, 1.0)
        angle = np.arccos(cos_angle)
        
        return np.degrees(angle)


class MainWindow(QMainWindow):
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ìœˆë„ìš°"""
    
    def __init__(self):
        super().__init__()
        self.video_path = None
        self.analysis_result = None
        self.timepoints = []
        
        self.init_ui()
    
    def init_ui(self):
        """UI ì´ˆê¸°í™”"""
        self.setWindowTitle("Parbiomech ë¹„ë””ì˜¤ ë¶„ì„")
        self.setGeometry(100, 100, 1200, 800)
        
        # ì¤‘ì•™ ìœ„ì ¯
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ë©”ì¸ ë ˆì´ì•„ì›ƒ
        layout = QVBoxLayout()
        central_widget.setLayout(layout)
        
        # íƒ€ì´í‹€
        title = QLabel("ğŸ¥ Parbiomech ë¹„ë””ì˜¤ ë¶„ì„ í”„ë¡œê·¸ë¨")
        title.setFont(QFont("Arial", 20, QFont.Bold))
        title.setAlignment(Qt.AlignCenter)
        layout.addWidget(title)
        
        # ë¹„ë””ì˜¤ ì—…ë¡œë“œ ì„¹ì…˜
        upload_group = QGroupBox("1. ë¹„ë””ì˜¤ ì—…ë¡œë“œ")
        upload_layout = QHBoxLayout()
        upload_group.setLayout(upload_layout)
        
        self.file_label = QLabel("ì„ íƒëœ íŒŒì¼ ì—†ìŒ")
        upload_layout.addWidget(self.file_label)
        
        self.upload_btn = QPushButton("ğŸ“ ë¹„ë””ì˜¤ ì„ íƒ")
        self.upload_btn.clicked.connect(self.select_video)
        upload_layout.addWidget(self.upload_btn)
        
        layout.addWidget(upload_group)
        
        # ì„¤ì • ì„¹ì…˜
        settings_group = QGroupBox("2. ë¶„ì„ ì„¤ì •")
        settings_layout = QVBoxLayout()
        settings_group.setLayout(settings_layout)
        
        # ì‹ ë¢°ë„ ì„¤ì •
        confidence_layout = QHBoxLayout()
        confidence_layout.addWidget(QLabel("ì‹ ë¢°ë„ ì„ê³„ê°’:"))
        
        self.confidence_slider = QSlider(Qt.Horizontal)
        self.confidence_slider.setMinimum(1)
        self.confidence_slider.setMaximum(10)
        self.confidence_slider.setValue(5)
        self.confidence_slider.valueChanged.connect(self.update_confidence_label)
        confidence_layout.addWidget(self.confidence_slider)
        
        self.confidence_label = QLabel("0.5")
        confidence_layout.addWidget(self.confidence_label)
        
        settings_layout.addLayout(confidence_layout)
        
        # íƒ€ì„í¬ì¸íŠ¸ ì„¤ì •
        timepoint_layout = QHBoxLayout()
        timepoint_layout.addWidget(QLabel("íƒ€ì„í¬ì¸íŠ¸ (ì´ˆ):"))
        
        self.timepoint_input = QTextEdit()
        self.timepoint_input.setMaximumHeight(60)
        self.timepoint_input.setPlaceholderText("ì˜ˆ: 0.5, 1.0, 2.5")
        timepoint_layout.addWidget(self.timepoint_input)
        
        settings_layout.addLayout(timepoint_layout)
        
        layout.addWidget(settings_group)
        
        # ë¶„ì„ ë²„íŠ¼
        self.analyze_btn = QPushButton("ğŸ” ë¶„ì„ ì‹œì‘")
        self.analyze_btn.setFont(QFont("Arial", 14, QFont.Bold))
        self.analyze_btn.setMinimumHeight(50)
        self.analyze_btn.clicked.connect(self.start_analysis)
        self.analyze_btn.setEnabled(False)
        layout.addWidget(self.analyze_btn)
        
        # ì§„í–‰ ìƒíƒœ
        self.status_label = QLabel("")
        layout.addWidget(self.status_label)
        
        self.progress_bar = QProgressBar()
        layout.addWidget(self.progress_bar)
        
        # ê²°ê³¼ íƒ­
        self.result_tabs = QTabWidget()
        layout.addWidget(self.result_tabs)
        
        # ìŠ¤íƒ€ì¼ ì ìš©
        self.setStyleSheet("""
            QGroupBox {
                font-weight: bold;
                border: 2px solid #cccccc;
                border-radius: 5px;
                margin-top: 10px;
                padding-top: 10px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px 0 5px;
            }
            QPushButton {
                background-color: #4CAF50;
                color: white;
                border: none;
                padding: 10px;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #45a049;
            }
            QPushButton:disabled {
                background-color: #cccccc;
            }
        """)
    
    def update_confidence_label(self, value):
        """ì‹ ë¢°ë„ ë¼ë²¨ ì—…ë°ì´íŠ¸"""
        self.confidence_label.setText(f"{value / 10:.1f}")
    
    def select_video(self):
        """ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ"""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ",
            "",
            "Video Files (*.mp4 *.avi *.mov *.mkv);;All Files (*)"
        )
        
        if file_path:
            self.video_path = file_path
            self.file_label.setText(f"ì„ íƒë¨: {Path(file_path).name}")
            self.analyze_btn.setEnabled(True)
    
    def start_analysis(self):
        """ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘"""
        # íƒ€ì„í¬ì¸íŠ¸ íŒŒì‹±
        timepoint_text = self.timepoint_input.toPlainText().strip()
        if timepoint_text:
            try:
                self.timepoints = [float(x.strip()) for x in timepoint_text.split(',')]
            except:
                QMessageBox.warning(self, "ì…ë ¥ ì˜¤ë¥˜", "íƒ€ì„í¬ì¸íŠ¸ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return
        else:
            self.timepoints = []
        
        confidence = self.confidence_slider.value() / 10.0
        
        # UI ë¹„í™œì„±í™”
        self.analyze_btn.setEnabled(False)
        self.upload_btn.setEnabled(False)
        
        # ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘
        self.analysis_thread = VideoAnalysisThread(
            self.video_path,
            self.timepoints,
            confidence
        )
        self.analysis_thread.progress.connect(self.update_progress)
        self.analysis_thread.status.connect(self.update_status)
        self.analysis_thread.finished.connect(self.analysis_complete)
        self.analysis_thread.error.connect(self.analysis_error)
        self.analysis_thread.start()
    
    def update_progress(self, value):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        self.progress_bar.setValue(value)
    
    def update_status(self, message):
        """ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸"""
        self.status_label.setText(message)
    
    def analysis_complete(self, result):
        """ë¶„ì„ ì™„ë£Œ ì²˜ë¦¬"""
        self.analysis_result = result
        
        # UI ì¬í™œì„±í™”
        self.analyze_btn.setEnabled(True)
        self.upload_btn.setEnabled(True)
        
        # ê²°ê³¼ í‘œì‹œ
        self.display_results(result)
        
        QMessageBox.information(self, "ì™„ë£Œ", "ë¹„ë””ì˜¤ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    def analysis_error(self, error_msg):
        """ë¶„ì„ ì˜¤ë¥˜ ì²˜ë¦¬"""
        self.analyze_btn.setEnabled(True)
        self.upload_btn.setEnabled(True)
        
        QMessageBox.critical(self, "ì˜¤ë¥˜", f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{error_msg}")
    
    def display_results(self, result):
        """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        # ê¸°ì¡´ íƒ­ ì œê±°
        self.result_tabs.clear()
        
        # íƒ€ì„í¬ì¸íŠ¸ ê²°ê³¼ íƒ­
        if result['timepoint_results']:
            timepoint_widget = QTableWidget()
            timepoint_widget.setColumnCount(3)
            timepoint_widget.setHorizontalHeaderLabels(['ì‹œê°„ (ì´ˆ)', 'í”„ë ˆì„', 'ì™¼ìª½ íŒ”ê¿ˆì¹˜ ê°ë„'])
            timepoint_widget.setRowCount(len(result['timepoint_results']))
            
            for i, (time, data) in enumerate(result['timepoint_results'].items()):
                timepoint_widget.setItem(i, 0, QTableWidgetItem(f"{time:.2f}"))
                timepoint_widget.setItem(i, 1, QTableWidgetItem(str(data['frame'])))
                timepoint_widget.setItem(i, 2, QTableWidgetItem(f"{data['left_elbow_angle']:.1f}Â°"))
            
            self.result_tabs.addTab(timepoint_widget, "íƒ€ì„í¬ì¸íŠ¸ ë¶„ì„")
        
        # ì¶”ì  ë°ì´í„° ì°¨íŠ¸
        if not result['tracking_data'].empty:
            chart_widget = pg.PlotWidget()
            chart_widget.setBackground('w')
            chart_widget.setLabel('left', 'ê°ë„ (ë„)')
            chart_widget.setLabel('bottom', 'ì‹œê°„ (ì´ˆ)')
            chart_widget.setTitle('ê¶¤ì  ë¶„ì„')
            
            # ì˜ˆì‹œ: nose Y ì¢Œí‘œ í”Œë¡¯
            times = result['tracking_data']['time'].values
            nose_y = result['tracking_data']['nose_y'].values
            chart_widget.plot(times, nose_y, pen='b', name='Nose Y')
            
            self.result_tabs.addTab(chart_widget, "ê¶¤ì  ì°¨íŠ¸")
        
        # ë¹„ë””ì˜¤ ê²½ë¡œ í‘œì‹œ
        video_info = QLabel(f"ë¶„ì„ëœ ë¹„ë””ì˜¤: {result['output_video']}\n\n"
                           f"ì´ íŒŒì¼ì„ ë¯¸ë””ì–´ í”Œë ˆì´ì–´ë¡œ ì—´ì–´ë³´ì„¸ìš”.")
        video_info.setWordWrap(True)
        self.result_tabs.addTab(video_info, "ë¹„ë””ì˜¤ ì •ë³´")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec_())


if __name__ == '__main__':
    main()
