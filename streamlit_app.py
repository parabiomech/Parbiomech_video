import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
import tempfile
import os
from pathlib import Path
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from PIL import Image
import io

# MediaPipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Keypoint Tracker - ë™ì‘ ë¶„ì„ ë„êµ¬",
    page_icon="ğŸ¯",
    layout="wide"
)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
    <style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    .stApp {
        background: white;
        border-radius: 20px;
        padding: 20px;
    }
    </style>
""", unsafe_allow_html=True)

# ì œëª©
st.title("ğŸ¯ Keypoint Tracker - ë™ì‘ ë¶„ì„ ë„êµ¬")
st.markdown("---")

# í¬ì¦ˆ ëœë“œë§ˆí¬ ì •ì˜
POSE_LANDMARKS = {
    0: "Nose", 11: "Left Shoulder", 12: "Right Shoulder",
    13: "Left Elbow", 14: "Right Elbow", 15: "Left Wrist", 16: "Right Wrist",
    23: "Left Hip", 24: "Right Hip", 25: "Left Knee", 26: "Right Knee",
    27: "Left Ankle", 28: "Right Ankle"
}

def calculate_angle(a, b, c):
    """ì„¸ ì ìœ¼ë¡œ ê°ë„ ê³„ì‚°"""
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    
    if angle > 180.0:
        angle = 360-angle
        
    return angle

def analyze_frame_at_time(video_path, time_sec, pose_detector):
    """íŠ¹ì • ì‹œì ì˜ í”„ë ˆì„ ë¶„ì„"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_num = int(time_sec * fps)
    
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        return None, None, None
    
    # RGBë¡œ ë³€í™˜
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # í¬ì¦ˆ ê°ì§€
    results = pose_detector.process(image_rgb)
    
    # í¬ì¦ˆ ê·¸ë¦¬ê¸°
    annotated_frame = frame.copy()
    angles = {}
    
    if results.pose_landmarks:
        # í¬ì¦ˆ ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
        mp_drawing.draw_landmarks(
            annotated_frame,
            results.pose_landmarks,
            mp_pose.POSE_CONNECTIONS,
            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()
        )
        
        landmarks = results.pose_landmarks.landmark
        
        # ì£¼ìš” ê°ë„ ê³„ì‚°
        # ì™¼ìª½ íŒ”ê¿ˆì¹˜
        if all(landmarks[i].visibility > 0.5 for i in [11, 13, 15]):
            shoulder = [landmarks[11].x, landmarks[11].y]
            elbow = [landmarks[13].x, landmarks[13].y]
            wrist = [landmarks[15].x, landmarks[15].y]
            angles['ì™¼ìª½ íŒ”ê¿ˆì¹˜'] = calculate_angle(shoulder, elbow, wrist)
        
        # ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜
        if all(landmarks[i].visibility > 0.5 for i in [12, 14, 16]):
            shoulder = [landmarks[12].x, landmarks[12].y]
            elbow = [landmarks[14].x, landmarks[14].y]
            wrist = [landmarks[16].x, landmarks[16].y]
            angles['ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜'] = calculate_angle(shoulder, elbow, wrist)
        
        # ì™¼ìª½ ë¬´ë¦
        if all(landmarks[i].visibility > 0.5 for i in [23, 25, 27]):
            hip = [landmarks[23].x, landmarks[23].y]
            knee = [landmarks[25].x, landmarks[25].y]
            ankle = [landmarks[27].x, landmarks[27].y]
            angles['ì™¼ìª½ ë¬´ë¦'] = calculate_angle(hip, knee, ankle)
        
        # ì˜¤ë¥¸ìª½ ë¬´ë¦
        if all(landmarks[i].visibility > 0.5 for i in [24, 26, 28]):
            hip = [landmarks[24].x, landmarks[24].y]
            knee = [landmarks[26].x, landmarks[26].y]
            ankle = [landmarks[28].x, landmarks[28].y]
            angles['ì˜¤ë¥¸ìª½ ë¬´ë¦'] = calculate_angle(hip, knee, ankle)
        
        # ì™¼ìª½ ê³ ê´€ì ˆ
        if all(landmarks[i].visibility > 0.5 for i in [11, 23, 25]):
            shoulder = [landmarks[11].x, landmarks[11].y]
            hip = [landmarks[23].x, landmarks[23].y]
            knee = [landmarks[25].x, landmarks[25].y]
            angles['ì™¼ìª½ ê³ ê´€ì ˆ'] = calculate_angle(shoulder, hip, knee)
        
        # ì˜¤ë¥¸ìª½ ê³ ê´€ì ˆ
        if all(landmarks[i].visibility > 0.5 for i in [12, 24, 26]):
            shoulder = [landmarks[12].x, landmarks[12].y]
            hip = [landmarks[24].x, landmarks[24].y]
            knee = [landmarks[26].x, landmarks[26].y]
            angles['ì˜¤ë¥¸ìª½ ê³ ê´€ì ˆ'] = calculate_angle(shoulder, hip, knee)
    
    # BGR to RGB for display
    annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
    
    return annotated_frame_rgb, angles, results.pose_landmarks is not None

def apply_lowpass_filter(data, strength=5):
    """ë¡œìš°íŒ¨ìŠ¤ í•„í„° ì ìš©"""
    if len(data) == 0:
        return data
    
    filtered = []
    for i in range(len(data)):
        start = max(0, i - strength)
        end = min(len(data), i + strength + 1)
        filtered.append(np.mean(data[start:end]))
    
    return filtered

def process_video(video_file, confidence_threshold=0.5, filter_strength=5):
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ"""
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    tfile.write(video_file.read())
    tfile.close()
    
    # ë¹„ë””ì˜¤ ìº¡ì²˜
    cap = cv2.VideoCapture(tfile.name)
    
    # ë¹„ë””ì˜¤ ì •ë³´
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    tracking_data = []
    angle_data = []
    processed_frames = []  # í”„ë ˆì„ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # MediaPipe Pose ì´ˆê¸°í™” (model_complexity=1ë¡œ ë³€ê²½í•˜ì—¬ ê¶Œí•œ ë¬¸ì œ íšŒí”¼)
    with mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,
        min_detection_confidence=confidence_threshold,
        min_tracking_confidence=confidence_threshold
    ) as pose:
        
        frame_num = 0
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # RGBë¡œ ë³€í™˜
            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # í¬ì¦ˆ ê°ì§€
            results = pose.process(image_rgb)
            
            # í¬ì¦ˆ ê·¸ë¦¬ê¸°
            annotated_frame = frame.copy()
            if results.pose_landmarks:
                # í¬ì¦ˆ ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                mp_drawing.draw_landmarks(
                    annotated_frame,
                    results.pose_landmarks,
                    mp_pose.POSE_CONNECTIONS,
                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()
                )
            
            # í”„ë ˆì„ì„ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
            processed_frames.append(annotated_frame)
            
            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                
                # í”„ë ˆì„ë³„ í‚¤í¬ì¸íŠ¸ ì €ì¥
                frame_data = {'frame': frame_num, 'time': frame_num / fps}
                
                for idx, name in POSE_LANDMARKS.items():
                    lm = landmarks[idx]
                    frame_data[f'{name}_x'] = lm.x
                    frame_data[f'{name}_y'] = lm.y
                    frame_data[f'{name}_z'] = lm.z
                    frame_data[f'{name}_visibility'] = lm.visibility
                
                tracking_data.append(frame_data)
                
                # ê°ë„ ê³„ì‚°
                angles = {}
                
                # ì™¼ìª½ íŒ”ê¿ˆì¹˜ ê°ë„
                if all(landmarks[i].visibility > confidence_threshold for i in [11, 13, 15]):
                    shoulder = [landmarks[11].x, landmarks[11].y]
                    elbow = [landmarks[13].x, landmarks[13].y]
                    wrist = [landmarks[15].x, landmarks[15].y]
                    angles['left_elbow'] = calculate_angle(shoulder, elbow, wrist)
                
                # ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜ ê°ë„
                if all(landmarks[i].visibility > confidence_threshold for i in [12, 14, 16]):
                    shoulder = [landmarks[12].x, landmarks[12].y]
                    elbow = [landmarks[14].x, landmarks[14].y]
                    wrist = [landmarks[16].x, landmarks[16].y]
                    angles['right_elbow'] = calculate_angle(shoulder, elbow, wrist)
                
                # ì™¼ìª½ ë¬´ë¦ ê°ë„
                if all(landmarks[i].visibility > confidence_threshold for i in [23, 25, 27]):
                    hip = [landmarks[23].x, landmarks[23].y]
                    knee = [landmarks[25].x, landmarks[25].y]
                    ankle = [landmarks[27].x, landmarks[27].y]
                    angles['left_knee'] = calculate_angle(hip, knee, ankle)
                
                # ì˜¤ë¥¸ìª½ ë¬´ë¦ ê°ë„
                if all(landmarks[i].visibility > confidence_threshold for i in [24, 26, 28]):
                    hip = [landmarks[24].x, landmarks[24].y]
                    knee = [landmarks[26].x, landmarks[26].y]
                    ankle = [landmarks[28].x, landmarks[28].y]
                    angles['right_knee'] = calculate_angle(hip, knee, ankle)
                
                # ì™¼ìª½ ê³ ê´€ì ˆ ê°ë„
                if all(landmarks[i].visibility > confidence_threshold for i in [11, 23, 25]):
                    shoulder = [landmarks[11].x, landmarks[11].y]
                    hip = [landmarks[23].x, landmarks[23].y]
                    knee = [landmarks[25].x, landmarks[25].y]
                    angles['left_hip'] = calculate_angle(shoulder, hip, knee)
                
                # ì˜¤ë¥¸ìª½ ê³ ê´€ì ˆ ê°ë„
                if all(landmarks[i].visibility > confidence_threshold for i in [12, 24, 26]):
                    shoulder = [landmarks[12].x, landmarks[12].y]
                    hip = [landmarks[24].x, landmarks[24].y]
                    knee = [landmarks[26].x, landmarks[26].y]
                    angles['right_hip'] = calculate_angle(shoulder, hip, knee)
                
                angles['frame'] = frame_num
                angles['time'] = frame_num / fps
                angle_data.append(angles)
            
            frame_num += 1
            progress = frame_num / total_frames
            progress_bar.progress(progress)
            status_text.text(f"ì²˜ë¦¬ ì¤‘: {frame_num}/{total_frames} í”„ë ˆì„")
    
    cap.release()
    os.unlink(tfile.name)
    
    # í”„ë ˆì„ì„ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥
    output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_file.name, fourcc, fps, (width, height))
    
    for frame in processed_frames:
        out.write(frame)
    
    out.release()
    
    progress_bar.empty()
    status_text.empty()
    
    # DataFrameìœ¼ë¡œ ë³€í™˜
    df_tracking = pd.DataFrame(tracking_data)
    df_angles = pd.DataFrame(angle_data)
    
    # í•„í„° ì ìš©
    if filter_strength > 0 and len(df_angles) > 0:
        for col in df_angles.columns:
            if col not in ['frame', 'time']:
                df_angles[col] = apply_lowpass_filter(df_angles[col].values, filter_strength)
    
    return df_tracking, df_angles, fps, width, height, output_file.name

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    confidence = st.slider(
        "ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.1,
        help="í¬ì¦ˆ ê°ì§€ì˜ ìµœì†Œ ì‹ ë¢°ë„"
    )
    
    filter_strength = st.slider(
        "í•„í„° ê°•ë„",
        min_value=0,
        max_value=20,
        value=5,
        help="ë°ì´í„° ìŠ¤ë¬´ë”© ì •ë„ (0 = í•„í„° ì—†ìŒ)"
    )
    
    st.markdown("---")
    st.markdown("""
    ### ğŸ“‹ ì‚¬ìš© ë°©ë²•
    1. ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ
    2. ì²˜ë¦¬ ì‹œì‘
    3. ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
    
    ### ğŸ“Š ë¶„ì„ í•­ëª©
    - ê´€ì ˆ ê°ë„ ë¶„ì„
    - í‚¤í¬ì¸íŠ¸ ê¶¤ì 
    - ì‹œê°„ë³„ ë³€í™” ê·¸ë˜í”„
    """)

# ë©”ì¸ ì˜ì—­
uploaded_file = st.file_uploader(
    "ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
    type=['mp4', 'mov', 'avi', 'mkv'],
    help="ë™ì‘ ë¶„ì„ì„ ìœ„í•œ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”"
)

if uploaded_file is not None:
    st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
    
    # ì›ë³¸ ë¹„ë””ì˜¤ í‘œì‹œ
    st.markdown("---")
    st.header("ğŸ“¹ ì›ë³¸ ë¹„ë””ì˜¤")
    
    # ë¹„ë””ì˜¤ íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ê¸° (ì¬ì‚¬ìš©ì„ ìœ„í•´ ì„¸ì…˜ì— ì €ì¥)
    if 'original_video_bytes' not in st.session_state or st.session_state.get('last_uploaded_file') != uploaded_file.name:
        video_bytes = uploaded_file.read()
        st.session_state['original_video_bytes'] = video_bytes
        st.session_state['last_uploaded_file'] = uploaded_file.name
        # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦¼
        uploaded_file.seek(0)
    
    # ì›ë³¸ ë¹„ë””ì˜¤ í‘œì‹œ
    st.video(st.session_state['original_video_bytes'])
    
    st.markdown("---")
    
    col1, col2 = st.columns([1, 4])
    
    with col1:
        if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
            with st.spinner("ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘..."):
                df_tracking, df_angles, fps, width, height, output_video_path = process_video(
                    uploaded_file,
                    confidence,
                    filter_strength
                )
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['df_tracking'] = df_tracking
                st.session_state['df_angles'] = df_angles
                st.session_state['fps'] = fps
                st.session_state['video_info'] = f"{width}x{height} @ {fps}fps"
                st.session_state['output_video_path'] = output_video_path
                
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

# ê²°ê³¼ í‘œì‹œ
if 'df_tracking' in st.session_state and 'df_angles' in st.session_state:
    df_tracking = st.session_state['df_tracking']
    df_angles = st.session_state['df_angles']
    
    st.markdown("---")
    st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    # ë¹„ë””ì˜¤ ì •ë³´
    info_col1, info_col2, info_col3 = st.columns(3)
    with info_col1:
        st.metric("ì´ í”„ë ˆì„", len(df_tracking))
    with info_col2:
        st.metric("ë¹„ë””ì˜¤ ì •ë³´", st.session_state['video_info'])
    with info_col3:
        st.metric("ë¶„ì„ ì‹œê°„", f"{len(df_tracking) / st.session_state['fps']:.2f}ì´ˆ")
    
    # íƒ­ìœ¼ë¡œ ê²°ê³¼ êµ¬ë¶„
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ¥ ë¶„ì„ ê²°ê³¼ ë¹„ë””ì˜¤", "â±ï¸ ì‹œì  ë¶„ì„", "ğŸ“ˆ ê´€ì ˆ ê°ë„", "ğŸ“ ê¶¤ì  ë¶„ì„", "ğŸ’¾ ë‹¤ìš´ë¡œë“œ"])
    
    with tab1:
        st.subheader("í¬ì¦ˆ ìŠ¤ì¼ˆë ˆí†¤ ê°ì§€ ê²°ê³¼")
        
        if 'output_video_path' in st.session_state and os.path.exists(st.session_state['output_video_path']):
            video_path = st.session_state['output_video_path']
            
            try:
                with open(video_path, 'rb') as video_file:
                    video_bytes = video_file.read()
                
                if len(video_bytes) > 0:
                    # ë¹„ë””ì˜¤ í‘œì‹œ
                    st.video(video_bytes)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        st.download_button(
                            label="ğŸ“¥ ë¶„ì„ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
                            data=video_bytes,
                            file_name="pose_analysis_video.mp4",
                            mime="video/mp4",
                            use_container_width=True
                        )
                    
                    with col2:
                        st.info(f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: {st.session_state['video_info']}")
                else:
                    st.error("ë¹„ë””ì˜¤ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¶„ì„í•´ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"ë¹„ë””ì˜¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                st.info("ë‹¤ì‹œ ë¶„ì„ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            st.info("ë¹„ë””ì˜¤ ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
            if 'output_video_path' in st.session_state:
                st.warning(f"íŒŒì¼ ê²½ë¡œ: {st.session_state.get('output_video_path', 'N/A')}")
                st.warning("íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    
    with tab2:
        st.subheader("â±ï¸ ì‹œì ë³„ ë™ì‘ ë¶„ì„")
        
        if 'original_video_bytes' in st.session_state and 'df_tracking' in st.session_state:
            # ë¹„ë””ì˜¤ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_video = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            temp_video.write(st.session_state['original_video_bytes'])
            temp_video.close()
            
            # ë¹„ë””ì˜¤ ì •ë³´
            total_time = len(st.session_state['df_tracking']) / st.session_state['fps']
            
            st.info(f"ğŸ“¹ ë¹„ë””ì˜¤ ê¸¸ì´: {total_time:.2f}ì´ˆ")
            
            # ì‹œì  ì…ë ¥ ì„¹ì…˜
            st.markdown("### ì‹œì  ì§€ì •")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                # ì‹œì  ì¶”ê°€ ë°©ë²• ì„ íƒ
                method = st.radio(
                    "ì‹œì  ì§€ì • ë°©ë²•",
                    ["ìŠ¬ë¼ì´ë”ë¡œ ì„ íƒ", "ì§ì ‘ ì…ë ¥"],
                    horizontal=True
                )
            
            # ì‹œì  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
            if 'timepoints' not in st.session_state:
                st.session_state['timepoints'] = []
            
            if method == "ìŠ¬ë¼ì´ë”ë¡œ ì„ íƒ":
                selected_time = st.slider(
                    "ì‹œì  ì„ íƒ (ì´ˆ)",
                    min_value=0.0,
                    max_value=total_time,
                    value=0.0,
                    step=0.1
                )
            else:
                selected_time = st.number_input(
                    "ì‹œì  ì…ë ¥ (ì´ˆ)",
                    min_value=0.0,
                    max_value=total_time,
                    value=0.0,
                    step=0.1
                )
            
            col1, col2, col3 = st.columns([1, 1, 2])
            
            with col1:
                if st.button("â• ì‹œì  ì¶”ê°€", use_container_width=True):
                    if selected_time not in st.session_state['timepoints']:
                        st.session_state['timepoints'].append(selected_time)
                        st.session_state['timepoints'].sort()
                        st.success(f"ì‹œì  {selected_time:.2f}ì´ˆ ì¶”ê°€ë¨")
                    else:
                        st.warning("ì´ë¯¸ ì¶”ê°€ëœ ì‹œì ì…ë‹ˆë‹¤.")
            
            with col2:
                if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", use_container_width=True):
                    st.session_state['timepoints'] = []
                    st.success("ëª¨ë“  ì‹œì ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # í˜„ì¬ ì‹œì  ëª©ë¡
            if st.session_state['timepoints']:
                st.markdown("### ğŸ“‹ ì§€ì •ëœ ì‹œì ")
                
                # ì‹œì  í‘œì‹œ ë° ê°œë³„ ì‚­ì œ
                cols = st.columns(min(len(st.session_state['timepoints']), 5))
                for idx, time_point in enumerate(st.session_state['timepoints']):
                    with cols[idx % 5]:
                        if st.button(f"âŒ {time_point:.2f}ì´ˆ", key=f"del_{idx}"):
                            st.session_state['timepoints'].remove(time_point)
                            st.rerun()
                
                st.markdown("---")
                
                # ë¶„ì„ ì‹œì‘
                if st.button("ğŸ” ì‹œì ë³„ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                    with st.spinner("ì‹œì ë³„ ë¶„ì„ ì¤‘..."):
                        # MediaPipe Pose ì´ˆê¸°í™”
                        with mp_pose.Pose(
                            static_image_mode=True,
                            model_complexity=1,
                            min_detection_confidence=0.5
                        ) as pose:
                            timepoint_results = []
                            
                            for time_point in st.session_state['timepoints']:
                                frame, angles, detected = analyze_frame_at_time(
                                    temp_video.name,
                                    time_point,
                                    pose
                                )
                                
                                if frame is not None:
                                    timepoint_results.append({
                                        'time': time_point,
                                        'frame': frame,
                                        'angles': angles,
                                        'detected': detected
                                    })
                            
                            st.session_state['timepoint_results'] = timepoint_results
                    
                    st.success("âœ… ì‹œì ë³„ ë¶„ì„ ì™„ë£Œ!")
                
                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                if 'timepoint_results' in st.session_state and st.session_state['timepoint_results']:
                    st.markdown("---")
                    st.markdown("### ğŸ“Š ì‹œì ë³„ ë¶„ì„ ê²°ê³¼")
                    
                    results = st.session_state['timepoint_results']
                    
                    # ì‹œì ë³„ë¡œ í‘œì‹œ
                    for idx, result in enumerate(results):
                        st.markdown(f"#### ì‹œì  {idx + 1}: {result['time']:.2f}ì´ˆ")
                        
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            # í¬ì¦ˆê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
                            st.image(result['frame'], caption=f"{result['time']:.2f}ì´ˆ", use_container_width=True)
                        
                        with col2:
                            # ê°ë„ ì •ë³´
                            if result['detected'] and result['angles']:
                                st.markdown("**ğŸ”¢ ê´€ì ˆ ê°ë„**")
                                for joint, angle in result['angles'].items():
                                    st.metric(joint, f"{angle:.1f}Â°")
                            else:
                                st.warning("í¬ì¦ˆë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        
                        st.markdown("---")
                    
                    # ì‹œì ê°„ ê°ë„ ë¹„êµ ê·¸ë˜í”„
                    if len(results) > 1:
                        st.markdown("### ğŸ“ˆ ì‹œì ê°„ ê°ë„ ë¹„êµ")
                        
                        # ëª¨ë“  ê´€ì ˆ ì´ë¦„ ìˆ˜ì§‘
                        all_joints = set()
                        for result in results:
                            if result['angles']:
                                all_joints.update(result['angles'].keys())
                        
                        if all_joints:
                            selected_joints = st.multiselect(
                                "ë¹„êµí•  ê´€ì ˆ ì„ íƒ",
                                list(all_joints),
                                default=list(all_joints)[:3] if len(all_joints) >= 3 else list(all_joints)
                            )
                            
                            if selected_joints:
                                fig = go.Figure()
                                
                                for joint in selected_joints:
                                    times = []
                                    angles = []
                                    
                                    for result in results:
                                        if joint in result['angles']:
                                            times.append(result['time'])
                                            angles.append(result['angles'][joint])
                                    
                                    if times:
                                        fig.add_trace(go.Scatter(
                                            x=times,
                                            y=angles,
                                            mode='lines+markers',
                                            name=joint,
                                            marker=dict(size=12),
                                            line=dict(width=3)
                                        ))
                                
                                fig.update_layout(
                                    title="ì‹œì ë³„ ê´€ì ˆ ê°ë„ ë³€í™”",
                                    xaxis_title="ì‹œê°„ (ì´ˆ)",
                                    yaxis_title="ê°ë„ (ë„)",
                                    height=500,
                                    hovermode='x unified'
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ğŸ‘† ì‹œì ì„ ì¶”ê°€í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                os.unlink(temp_video.name)
            except:
                pass
        else:
            st.info("ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¨¼ì € ì „ì²´ ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    
    with tab3:
        st.subheader("ê´€ì ˆ ê°ë„ ë³€í™”")
        
        if len(df_angles) > 0:
            # ê°ë„ ì„ íƒ
            available_angles = [col for col in df_angles.columns if col not in ['frame', 'time']]
            selected_angles = st.multiselect(
                "í‘œì‹œí•  ê´€ì ˆ ì„ íƒ",
                available_angles,
                default=available_angles[:3] if len(available_angles) >= 3 else available_angles
            )
            
            if selected_angles:
                # Plotly ê·¸ë˜í”„ ìƒì„±
                fig = go.Figure()
                
                for angle in selected_angles:
                    fig.add_trace(go.Scatter(
                        x=df_angles['time'],
                        y=df_angles[angle],
                        mode='lines',
                        name=angle.replace('_', ' ').title(),
                        line=dict(width=2)
                    ))
                
                fig.update_layout(
                    title="ê´€ì ˆ ê°ë„ ë³€í™”",
                    xaxis_title="ì‹œê°„ (ì´ˆ)",
                    yaxis_title="ê°ë„ (ë„)",
                    hovermode='x unified',
                    height=500
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # í†µê³„ ì •ë³´
                st.subheader("ğŸ“Š í†µê³„ ì •ë³´")
                stats_df = df_angles[selected_angles].describe()
                st.dataframe(stats_df, use_container_width=True)
        else:
            st.warning("ê°ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab4:
        st.subheader("í‚¤í¬ì¸íŠ¸ ê¶¤ì  ë¶„ì„")
        
        # í‚¤í¬ì¸íŠ¸ ì»¬ëŸ¼ ì¶”ì¶œ
        keypoint_cols = [col for col in df_tracking.columns if col not in ['frame', 'time']]
        
        if keypoint_cols:
            # í‚¤í¬ì¸íŠ¸ ì„ íƒ
            col1, col2 = st.columns([1, 3])
            
            with col1:
                keypoints = list(set([col.rsplit('_', 1)[0] for col in keypoint_cols if '_x' in col or '_y' in col]))
                selected_keypoint = st.selectbox("í‚¤í¬ì¸íŠ¸ ì„ íƒ", keypoints)
            
            if selected_keypoint:
                x_col = f"{selected_keypoint}_x"
                y_col = f"{selected_keypoint}_y"
                
                if x_col in df_tracking.columns and y_col in df_tracking.columns:
                    # ê¶¤ì  ê·¸ë˜í”„
                    fig = go.Figure()
                    
                    fig.add_trace(go.Scatter(
                        x=df_tracking[x_col],
                        y=df_tracking[y_col],
                        mode='lines+markers',
                        name=selected_keypoint.replace('_', ' ').title(),
                        marker=dict(
                            size=4,
                            color=df_tracking['frame'],
                            colorscale='Viridis',
                            showscale=True,
                            colorbar=dict(title="í”„ë ˆì„")
                        ),
                        line=dict(width=2),
                        hovertemplate='<b>í”„ë ˆì„: %{marker.color}</b><br>X: %{x:.3f}<br>Y: %{y:.3f}<extra></extra>'
                    ))
                    
                    fig.update_layout(
                        title=f"{selected_keypoint.replace('_', ' ').title()} ê¶¤ì ",
                        xaxis_title="X ì¢Œí‘œ",
                        yaxis_title="Y ì¢Œí‘œ",
                        yaxis=dict(scaleanchor="x", scaleratio=1, autorange="reversed"),
                        height=500
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ì‹œê°„ë³„ ì¢Œí‘œ ë³€í™”
                    st.subheader("ì‹œê°„ë³„ ì¢Œí‘œ ë³€í™”")
                    
                    fig2 = make_subplots(
                        rows=2, cols=1,
                        subplot_titles=('X ì¢Œí‘œ ë³€í™”', 'Y ì¢Œí‘œ ë³€í™”'),
                        vertical_spacing=0.1
                    )
                    
                    fig2.add_trace(
                        go.Scatter(x=df_tracking['time'], y=df_tracking[x_col], 
                                   mode='lines', name='X', line=dict(color='blue')),
                        row=1, col=1
                    )
                    
                    fig2.add_trace(
                        go.Scatter(x=df_tracking['time'], y=df_tracking[y_col], 
                                   mode='lines', name='Y', line=dict(color='red')),
                        row=2, col=1
                    )
                    
                    fig2.update_xaxes(title_text="ì‹œê°„ (ì´ˆ)", row=2, col=1)
                    fig2.update_yaxes(title_text="X ì¢Œí‘œ", row=1, col=1)
                    fig2.update_yaxes(title_text="Y ì¢Œí‘œ", row=2, col=1)
                    fig2.update_layout(height=600, showlegend=False)
                    
                    st.plotly_chart(fig2, use_container_width=True)
                    
                    # í‚¤í¬ì¸íŠ¸ ë°ì´í„° í…Œì´ë¸”
                    st.subheader("ğŸ“Š í‚¤í¬ì¸íŠ¸ ë°ì´í„°")
                    st.dataframe(df_tracking, use_container_width=True, height=300)
        else:
            st.warning("í‚¤í¬ì¸íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab5:
        st.subheader("ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # í‚¤í¬ì¸íŠ¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            csv_tracking = df_tracking.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ í‚¤í¬ì¸íŠ¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                data=csv_tracking,
                file_name="keypoint_tracking_data.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col2:
            # ê°ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if len(df_angles) > 0:
                csv_angles = df_angles.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ ê°ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_angles,
                    file_name="angle_data.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            else:
                st.info("ê°ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

else:
    st.info("ğŸ‘† ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>Keypoint Tracker v1.0 | Powered by MediaPipe & Streamlit</p>
</div>
""", unsafe_allow_html=True)
